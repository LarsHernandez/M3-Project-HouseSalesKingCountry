---
title: "SDS 2019 - M3: Group Assignment"
author: "Andreas, Simon, Jess, Lars"
date: "14/9/2019"
output:
  html_document:
    code_folding: hide
    theme: flatly
    toc: yes
    toc_float:
      collapsed: no
---

# House prices King County

```{r message=FALSE, warning=FALSE}

#devtools::install_github("thomasp85/patchwork")
library(tidyverse)
library(keras)
library(caret)
library(patchwork)
library(knitr)
library(kableExtra)
library(ggmap)
library(tidymodels)
```


```{r message=FALSE, warning=FALSE}
kc <- read_csv("kc_house_data.csv")

kc$cluster <- kmeans(cbind(kc$lat, kc$long), centers = 100, nstart = 10, iter.max = 50)$cluster
```

```{r}
head(kc)
```



```{r fig.height=5, fig.width=10}
range(kc$date)
difftime(range(kc$date)[1],range(kc$date)[2])

p1 <- kc %>% ggplot(aes(price))       + geom_histogram(bins=200) + labs(title="Price distribution")
p2 <- kc %>% ggplot(aes(date))        + geom_histogram(bins=56)  + labs(title="Date of sale")
p3 <- kc %>% ggplot(aes(yr_built))    + geom_histogram(bins=115) + labs(title="Date of construction")
p4 <- kc %>% ggplot(aes(grade))       + geom_bar()               + labs(title="House grade")
p5 <- kc %>% ggplot(aes(sqft_living)) + geom_histogram(bins=200) + labs(title="House Squarefeet")
p6 <- kc %>% ggplot(aes(round(bathrooms)))   + geom_bar()               + labs(title="House bathrooms")

p1 + p2 + p3 + p4 + p5 + p6
```


```{r fig.height=5, fig.width=10}
d1 <- kc %>% group_by(zipcode) %>% summarize(mean = mean(price)) %>% ggplot(aes(reorder(as.factor(zipcode),mean), mean)) + geom_col() + theme(axis.text.x = element_text(angle = 90))
d2 <- kc %>% group_by(view) %>% summarize(mean = mean(price)) %>% ggplot(aes(reorder(as.factor(view),mean), mean)) + geom_col()
d3 <- kc %>% group_by(bedrooms) %>% summarize(mean = mean(price)) %>% ggplot(aes(reorder(as.factor(bedrooms),mean), mean)) + geom_col()
d4 <- kc %>% group_by(waterfront) %>% summarize(mean = mean(price)) %>% ggplot(aes(reorder(as.factor(waterfront),mean), mean)) + geom_col()
d5 <- kc %>% group_by(condition) %>% summarize(mean = mean(price)) %>% ggplot(aes(reorder(as.factor(condition),mean), mean)) + geom_col()
d6 <- kc %>% group_by(grade) %>% summarize(mean = mean(price)) %>% ggplot(aes(reorder(as.factor(grade),mean), mean)) + geom_col()

d1+d2+d3 + plot_layout(nrow = 3)

d4 + d4 + d6


kc %>% group_by(yr_built) %>% summarize(mean = mean(price)) %>% ggplot(aes(reorder(as.factor(yr_built), yr_built), mean)) + geom_col()+ theme(axis.text.x = element_text(angle = 90))


kc %>% group_by(date) %>% summarize(mean = mean(price)) %>% ggplot(aes(date, mean)) + geom_point() + geom_smooth() 
```




```{r fig.height=6, fig.width=9, message=FALSE, warning=FALSE}
lat <- range(kc$lat)
lon <- range(kc$long)

coord <- as.matrix(data.frame(min = c(lon[1]-0.25, lat[1]-0.05), 
                              max = c(lon[2]+0.05, lat[2]+0.05), 
                              row.names = c("x","y")))

map13 <- get_stamenmap(coord, zoom = 10, maptype = "toner-lite", force=TRUE)

high <- "#084081"
low <- "#252525"

ggmap(map13) +
  labs(title="Map of King County - price", x=NULL, y=NULL)

ggmap(map13) +
  geom_point(data = kc, aes(long,lat, color=price/1000), alpha = 0.8) + 
  labs(title="Map of King County - price", subtitle = "21.613 housing sales in 2014 - 2016", color="Price in\n1000 USD")


ggmap(map13) +
  stat_density_2d(data=kc, aes(long,lat, fill=..level..), geom = "polygon", alpha = .7) + 
  labs(title="Map of King County - density", subtitle = "21.613 housing sales in 2014 - 2016", fill="Density of\nsales")

ggmap(map13) +
  geom_point(data = kc, aes(long,lat, fill=as.factor(zipcode)), alpha = 0.1, size=3, show.legend = F, color="black", shape=21) + 
  #scale_fill_grey(start = 0.1, end = 0.9) +
  labs(title="Map of King County - price", subtitle = "21.613 housing sales in 2014 - 2016", x=NULL, y=NULL)

ggmap(map13) +
  geom_point(data = kc, aes(long,lat, fill=as.factor(cluster)), alpha = 0.1, size=3, show.legend = F, color="black", shape=21) + 
  #scale_fill_grey(start = 0.1, end = 0.9) +
  labs(title="Map of King County - price", subtitle = "21.613 housing sales in 2014 - 2016", x=NULL, y=NULL)
```





```{r fig.height=8, fig.width=10, message=FALSE, warning=FALSE}
coord <- as.matrix(data.frame(min = c(lon[1], lat[1]), 
                              max = c(lon[2]-0.5, lat[2]), 
                              row.names = c("x","y")))

map13 <- get_stamenmap(coord, zoom = 10, maptype = "toner-lite", force=TRUE)

p1 <- ggmap(map13) +
  stat_density_2d(data=subset(kc, price < 100000),  aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=low) +
  stat_density_2d(data=subset(kc, price > 500000), aes(long,lat, fill=..level..),  geom = "polygon", alpha = .3, fill=high) + 
  labs(title="Price > 500k & Price < 100k", x=NULL, y=NULL)

p2 <- ggmap(map13) +
  stat_density_2d(data=subset(kc, price < 150000),  aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=low) +
  stat_density_2d(data=subset(kc, price > 1000000), aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=high) + 
  labs(title="Price > 1m & Price < 150k", x=NULL, y=NULL)

p3 <- ggmap(map13) +
  stat_density_2d(data=subset(kc, price < 200000),  aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=low) +
  stat_density_2d(data=subset(kc, price > 2000000), aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=high) + 
  labs(title="Price > 2m & Price < 200k", x=NULL, y=NULL)

p4 <- ggmap(map13) +
  stat_density_2d(data=subset(kc, price < 300000),  aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=low) +
  stat_density_2d(data=subset(kc, price > 3000000), aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=high) + 
  labs(title="Price > 3m & Price < 300k", x=NULL, y=NULL)

p5 <- ggmap(map13) +
  stat_density_2d(data=subset(kc, price < 400000),  aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=low) +
  stat_density_2d(data=subset(kc, price > 4000000), aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=high) + 
  labs(title="Price > 4m & Price < 400k", x=NULL, y=NULL)

p6 <- ggmap(map13) +
  stat_density_2d(data=subset(kc, price < 500000),  aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=low) +
  stat_density_2d(data=subset(kc, price > 5000000), aes(long,lat, fill=..level..), geom = "polygon", alpha = .3, fill=high) + 
  labs(title="Price > 5m & Price < 500k", x=NULL, y=NULL)

p1+p2+p3+p4+p5+p6

kc$cut <- cut(log(kc$price), 12)
kc <- kc %>% group_by(cut) %>% mutate(mean = round(mean(price),-3))

ggmap(map13) +
  stat_density_2d(data=kc, aes(long,lat, fill=..level..), geom = "polygon", alpha = .2) +
  geom_point(data=kc, aes(long,lat), alpha=0.1, size=0.5) +
  scale_fill_viridis_c(option="cividis") +
  facet_wrap(~mean, nrow=3) + 
  labs(title="Price cut into 15 chunks", x=NULL, y=NULL)

ggmap(map13) +
  stat_density_2d(data=kc, aes(long,lat, fill=..level..), geom = "polygon", alpha = .7, show.legend = F) +
  geom_point(data=kc, aes(long,lat), alpha=0.1, size=0.5) +
    scale_fill_viridis_c(option = "cividis", rescaler = function(x, to = c(0, 17), from = NULL) {ifelse(x<17, scales::rescale(x,to = to,from = c(min(x, na.rm = TRUE), 17)),1)}) +
  facet_wrap(~mean, nrow=3) + 
  labs(title="Price cut into 15 chunks", x=NULL, y=NULL)

```





```{r}
skc <- kc %>% select(-id, -date) %>% 
  filter(bedrooms != 33) %>% 
  mutate_at(.vars = c("bedrooms", "bathrooms", "sqft_living", "sqft_lot", "condition", "grade", 
                      "sqft_above", "sqft_basement", "sqft_living15", "sqft_lot15", "long","lat"), scale) %>% 
  mutate_at(.vars = c("yr_built", "view", "waterfront", "floors", "yr_built", "yr_renovated", "zipcode", "cluster"), as.factor)

index    <- createDataPartition(skc$price, p = 0.8, list = FALSE)
training <- skc[index,] 
test     <- skc[-index,] 

paste0("The training set has ",  dim(training)[1], 
       " And the test set has ", dim(test)[1], " observations")

model_recipe <- recipe(price ~ ., data = training)

model_recipe_steps <- model_recipe %>% 
  step_dummy(yr_built, view, waterfront, floors, yr_built, yr_renovated, cluster, zipcode)
  #step_range(bedrooms, bathrooms, sqft_living, sqft_lot, condition, grade, sqft_above, 
  #           sqft_basement, sqft_living15, sqft_lot15, min = 0, max = 1)

prepped_recipe <- prep(model_recipe_steps, training = training)

training <- bake(prepped_recipe, training) 
test <- bake(prepped_recipe, test) 

x_train <- training %>% select(-price)
y_train <- training %>% select(price)

x_test <- test %>% select(-price)
y_test <- test %>% select(price)
```



```{r}
cv <- trainControl(method = "cv", number = 5)

t0 <- Sys.time()

fit_glm <- train(price     ~ .,
                 data      = training,
                 trControl = cv, 
                 tuneGrid  = expand.grid(alpha  = 0, lambda = 0),
                 method    = "glmnet", 
                 family    = "gaussian",
                 metric    = "RMSE")

t1 <- Sys.time()

fit_ela <- train(price     ~ .,
                 data      = training,
                 trControl = cv, 
                 tuneGrid  = expand.grid(alpha  = seq(0, 1,    by = 0.1),
                                         lambda = seq(1, 1000, by = 100)),
                 method    = "glmnet", 
                 family    = "gaussian",
                 metric    = "RMSE")

t2 <- Sys.time()

fit_tre <- train(price ~ .,
                 data      = training,
                 trControl = cv, 
                 method    = "rpart", 
                 metric    = 'RMSE')

t3 <- Sys.time()

fit_raf <- train(price     ~ ., 
                 data      = training,
                 trControl = cv,
                 tuneGrid  = expand.grid(.mtry = (1:2)),
                 method    = 'rf',
                 metric    = 'RMSE')

t4 <- Sys.time()

model <- keras_model_sequential() %>% 
  layer_dense(input_shape = dim(x_train)[2], units=256, activation="relu") %>% 
  layer_dense(units=128, activation="relu") %>% 
  layer_dense(1)


model %>%  compile(
  loss = "mae", 
  optimizer = "adam",
  metrics = list("mean_absolute_error"))

model %>% fit(
  as.matrix(x_train),
  as.matrix(y_train),
  epochs = 100,
  batch_size = 32,
  validation_split = 0.1)

pred <- predict(model, x=list(as.matrix(x_test),as.matrix(zip_test)))

t5 <- Sys.time()
```


```{r}
model %>% evaluate(list(as.matrix(x_test),as.matrix(zip_test)), as.matrix(y_test), verbose = 0)
```





```{r}
cat(paste0("Size of training set: ", nrow(training)," of 21613\n","\n",
           "lm:             ", round(difftime(t1,t0, units = "mins"),2),"\n",
           "Elastic:        ", round(difftime(t2,t1, units = "mins"),2),"\n",
           "Tree:           ", round(difftime(t3,t2, units = "mins"),2),"\n",
           "Random Forrest: ", round(difftime(t4,t3, units = "mins"),2),"\n",
           "Neural Net:     ", round(difftime(t5,t4, units = "mins"),2),"\n",
           "Total:          ", round(difftime(t5,t0, units = "mins"),2),"\n"))
```

```{r}
options(scipen=999)

MAE = function(m, o){
  mean(abs(m - o))
}


pred_glm <- predict(fit_glm,  newdata=test) %>% as.vector
mae_glm <- MAE(pred_glm, test$price)

pred_ela <- predict(fit_ela,  newdata=test) %>% as.vector
mae_ela <- MAE(pred_ela, test$price)

pred_tre <- predict(fit_tre,  newdata=test) %>% as.vector
mae_tre <- MAE(pred_tre, test$price)

pred_raf <- predict(fit_raf,  newdata=test) %>% as.vector
mae_raf <- MAE(pred_raf, test$price)

mae_nnt <- MAE(pred, test$price)

random   <- rep(mean(training$price), nrow(test))
mae_ran <- MAE(random, test$price)


kable(cbind(mae_glm, mae_ela, mae_tre, mae_raf, mae_nnt, mae_ran)) %>% 
  kable_styling("bordered", "condensed")

rbind(mae_glm, mae_ela, mae_tre, mae_raf, mae_nnt, mae_ran) %>% 
  as_tibble %>% 
  rename(mae = V1) %>% 
  mutate(Model = c("LinearModel", "ElasticNet", "RegressionTree", "RandomForrest", "NeuralNet","RandomAssignment")) %>% 
  ggplot(aes(reorder(Model, mae), mae)) + 
  geom_col() +
  labs(title="Model performance Mean Absolute Error")
```






```{r}

RMSE = function(m, o){
  sqrt(mean((m - o)^2))
}

MAE = function(m, o){
  mean(abs(m - o))
}


pred_glm <- predict(fit_glm,  newdata=test) %>% as.vector
rmse_glm <- RMSE(pred_glm, test$price)

pred_ela <- predict(fit_ela,  newdata=test) %>% as.vector
rmse_ela <- RMSE(pred_ela, test$price)

pred_tre <- predict(fit_tre,  newdata=test) %>% as.vector
rmse_tre <- RMSE(pred_tre, test$price)

pred_raf <- predict(fit_raf,  newdata=test) %>% as.vector
rmse_raf <- RMSE(pred_raf, test$price)


random   <- rep(mean(training$price), nrow(test))
rmse_ran <- RMSE(random, test$price)


kable(cbind(rmse_glm, rmse_ela, rmse_tre, rmse_raf, rmse_ran)) %>% 
  kable_styling("bordered", "condensed")

rbind(rmse_glm, rmse_ela, rmse_tre, rmse_raf, rmse_ran) %>% 
  as_tibble %>% 
  rename(RMSE = V1) %>% 
  mutate(Model = c("LinearModel", "ElasticNet", "RegressionTree", "RandomForrest", "RandomAssignment")) %>% 
  ggplot(aes(reorder(Model, RMSE), RMSE)) + 
  geom_col() +
  labs(title="Model performance RMSE")
```





```{r}
fit_ela <- train(price     ~ .,
                 data      = tra,
                 trControl = cv, 
                 tuneGrid  = expand.grid(alpha  = seq(0, 1,    by = 0.1),
                                         lambda = seq(0, 1000, by = 50)),
                 method    = "glmnet", 
                 family    = "gaussian",
                 metric    = "RMSE")

pred_ela <- predict(fit_ela,  newdata=tes) %>% as.vector

RMSE(pred_ela, tes$price)
MAE(pred_ela, tes$price)
```








```{r}
x_train <- tra %>% select(-price)
y_train <- tra %>% select(price)

x_test <- tes %>% select(-price)
y_test <- tes %>% select(price)

zip_train <- training$zipcode %>% as.character() %>% as.numeric()
zip_test <- test$zipcode %>% as.character() %>% as.numeric()

zipp <- tibble(z = zip_train) %>% mutate(z=as.factor(z)) %>% mutate(z=as.numeric(z))
zip_train <- zipp$z

main_input <- layer_input(shape = c(1), dtype = 'int32', name = 'main_input')

lstm_out <- main_input %>% 
  layer_embedding(input_dim = 200, output_dim = 5, input_length = 1) %>% 
    layer_flatten()

auxiliary_input <- layer_input(shape = c(dim(x_train)[2]), name = 'aux_input')

main_output <- layer_concatenate(c(lstm_out, auxiliary_input)) %>%  
  layer_dense(units = 64, activation = 'relu') %>% 
  layer_dropout(0.3) %>%
  layer_dense(units = 64, activation = 'relu') %>% 
  layer_dropout(0.2) %>%
  layer_dense(units = 1)

model <- keras_model(
  inputs = c(main_input, auxiliary_input), 
  outputs = c(main_output)
)

model %>%  compile(
  loss = "mse", 
  optimizer = "adam",
  metrics = "mean_absolute_error")

model %>% fit(
  x = list(as.matrix(zip_train), as.matrix(x_train)),
  y = as.matrix(y_train),
  epochs = 10,
  batch_size = 50,
  validation_split = 0.1)
```
















